# agent/graph.py - Updated with dual prompt system for psychological depth + conversion intelligence

import json
import time
import os
from typing import TypedDict, Dict, Any, List
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain.callbacks import LangChainTracer

# Import your external prompts and learning system
from prompts.research_prompts import ResearchPrompts
from agent.learning_memory import LearningMemorySystem

print("üîç LangSmith tracing is enabled")
print("üÜï Creating dual prompt system")

# Initialize learning system
learning_system = LearningMemorySystem()

class Level10ResearchState(TypedDict):
    # Input
    business_context: str
    research_type: str
    output_format: str
    
    # Dual analysis outputs
    psychological_analysis: str
    conversion_intelligence: str
    interview_insights: str
    synthesis_results: str
    
    # Combined outputs
    icp_analysis: str
    
    # Quality metrics
    quality_score: float
    confidence_score: float
    session_id: str
    
    # Learning and memory
    memory_context: Dict[str, Any]
    learning_insights: List[str]
    
    # Formatted outputs
    psychology_report: str
    campaign_insights: str
    voice_of_customer: List[str]

class ResearchConfig:
    """Configuration for research capabilities"""
    
    @staticmethod
    def get_llm(task_type: str):
        """Get optimized LLM for different tasks"""
        
        if task_type == "deep_psychological":
            # Use Claude for sophisticated psychological analysis
            llm = ChatAnthropic(
                model="claude-3-5-sonnet-20241022",
                temperature=0.2,
                max_tokens=4000,
                callbacks=[LangChainTracer()]
            )
        elif task_type == "conversion_intelligence":
            # Use Claude for conversion analysis
            llm = ChatAnthropic(
                model="claude-3-5-sonnet-20241022",
                temperature=0.3,
                max_tokens=4000,
                callbacks=[LangChainTracer()]
            )
        elif task_type == "creative_interviews":
            # Use GPT-4 for creative interview simulation
            llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.7,
                max_tokens=3000,
                callbacks=[LangChainTracer()]
            ) if os.getenv("OPENAI_API_KEY") else ChatAnthropic(
                model="claude-3-5-sonnet-20241022",
                temperature=0.7,
                max_tokens=3000,
                callbacks=[LangChainTracer()]
            )
        elif task_type == "synthesis":
            # Use Claude for campaign synthesis
            llm = ChatAnthropic(
                model="claude-3-5-sonnet-20241022", 
                temperature=0.3,
                max_tokens=4000,
                callbacks=[LangChainTracer()]
            )
        else:
            # Default Claude configuration
            llm = ChatAnthropic(
                model="claude-3-5-sonnet-20241022",
                temperature=0.2,
                callbacks=[LangChainTracer()]
            )
            
        return llm

def extract_industry(business_context: str) -> str:
    """Extract industry from business context for learning patterns"""
    context_lower = business_context.lower()
    
    if any(word in context_lower for word in ['financial', 'advisor', 'planning', 'investment']):
        return 'financial_services'
    elif any(word in context_lower for word in ['wellness', 'spa', 'health', 'recovery']):
        return 'wellness_health'
    elif any(word in context_lower for word in ['pet', 'dog', 'animal', 'treats']):
        return 'pet_products'
    elif any(word in context_lower for word in ['saas', 'software', 'tech', 'app']):
        return 'technology'
    elif any(word in context_lower for word in ['ecommerce', 'store', 'retail', 'product']):
        return 'ecommerce'
    elif any(word in context_lower for word in ['coach', 'consulting', 'service', 'agency']):
        return 'professional_services'
    else:
        return 'general'

def set_research_goal(state: Level10ResearchState) -> Level10ResearchState:
    """Initialize research with goal setting and memory context"""
    
    # Extract industry for learning context
    industry = extract_industry(state["business_context"])
    
    # Get accumulated learning for this industry
    learning_context = learning_system.get_learning_context_for_industry(industry)
    
    state["session_id"] = f"research_{int(time.time())}"
    state["memory_context"] = learning_context
    
    print(f"üéØ Research Goal: Dual analysis - Psychological depth + Conversion intelligence")
    print(f"üè≠ Industry Context: {industry}")
    print(f"üìö Memory Context: {len(learning_context.get('industry_specific_patterns', {}))} similar research sessions")
    print(f"üí° Optimization Suggestions: {len(learning_context.get('proven_techniques', []))} suggestions")
    
    return state

def conduct_dual_analysis_research(state: Level10ResearchState) -> Level10ResearchState:
    """Phase 1: Dual analysis - Deep psychological + conversion intelligence"""
    
    print("üß† Phase 1A: Deep Psychological Intelligence Analysis...")
    
    # First pass: Pure psychological depth
    psychological_llm = ResearchConfig.get_llm("deep_psychological")
    
    psych_prompt = ResearchPrompts.get_deep_psychological_research().format(
        business_context=state["business_context"],
        learning_context=json.dumps(state["memory_context"].get("framework_best_practices", {}), indent=2),
        industry_patterns=json.dumps(state["memory_context"].get("industry_specific_patterns", {}), indent=2)
    )
    
    psychological_result = psychological_llm.invoke(psych_prompt)
    state["psychological_analysis"] = psychological_result.content
    
    print("üéØ Phase 1B: Conversion Intelligence Analysis...")
    
    # Second pass: Conversion intelligence using psychological insights
    conversion_llm = ResearchConfig.get_llm("conversion_intelligence")
    
    conversion_prompt = ResearchPrompts.get_conversion_intelligence_research().format(
        psychological_analysis=psychological_result.content,
        business_context=state["business_context"]
    )
    
    conversion_result = conversion_llm.invoke(conversion_prompt)
    state["conversion_intelligence"] = conversion_result.content
    
    # Store combined analysis
    state["icp_analysis"] = f"""
# DEEP PSYCHOLOGICAL INTELLIGENCE ANALYSIS

{psychological_result.content}

---

# CONVERSION INTELLIGENCE APPLICATION

{conversion_result.content}
"""
    
    print(f"‚úÖ Dual analysis completed (Session: {state['session_id']})")
    
    return state

def simulate_enhanced_interviews(state: Level10ResearchState) -> Level10ResearchState:
    """Phase 2: Enhanced interview simulation using psychological insights"""
    
    print("üé≠ Phase 2: Simulating Enhanced Customer Interviews...")
    
    # Get creative LLM for interviews
    llm = ResearchConfig.get_llm("creative_interviews")
    
    # Enhanced interview prompt using psychological analysis
    prompt = ResearchPrompts.get_interview_simulation().format(
        psychological_analysis=state["psychological_analysis"]
    )
    
    result = llm.invoke(prompt)
    
    state["interview_insights"] = result.content
    
    print("‚úÖ Enhanced interview simulations completed")
    
    return state

def synthesize_campaign_intelligence(state: Level10ResearchState) -> Level10ResearchState:
    """Phase 3: Campaign synthesis combining all intelligence"""
    
    print("üöÄ Phase 3: Synthesizing Campaign Intelligence...")
    
    # Get synthesis LLM
    llm = ResearchConfig.get_llm("synthesis")
    
    # Enhanced synthesis using all previous analysis
    prompt = ResearchPrompts.get_campaign_synthesis().format(
        psychological_analysis=state["psychological_analysis"],
        conversion_intelligence=state["conversion_intelligence"],
        interview_insights=state["interview_insights"]
    )
    
    result = llm.invoke(prompt)
    
    state["synthesis_results"] = result.content
    
    # Extract VoC language patterns
    state["voice_of_customer"] = extract_voc_patterns(state)
    
    # Calculate enhanced quality scores
    state["quality_score"] = calculate_enhanced_quality_score(state)
    state["confidence_score"] = calculate_confidence_score(state)
    
    print(f"‚úÖ Campaign synthesis completed (Quality: {state['quality_score']:.1%})")
    
    return state

def learn_from_outcome(state: Level10ResearchState) -> Level10ResearchState:
    """Level 10: Learn from research outcome and update memory"""
    
    print("üß† Learning from dual analysis outcome...")
    
    # Prepare learning experience (no business-specific details)
    learning_experience = {
        "session_id": state["session_id"],
        "industry_context": extract_industry(state["business_context"]),
        "quality_score": state["quality_score"],
        "confidence_score": state["confidence_score"],
        "analysis_type": "dual_psychological_conversion",
        "framework_performance": {
            "psychological_depth": len(state["psychological_analysis"]) > 3000,
            "conversion_intelligence": len(state["conversion_intelligence"]) > 2000,
            "interview_authenticity": "realistic" in state["interview_insights"].lower(),
            "synthesis_completeness": len(state["synthesis_results"]) > 2000
        }
    }
    
    # Extract learning patterns (no contamination)
    learning_insights = learning_system.extract_learning_patterns(learning_experience)
    
    state["learning_insights"] = [
        f"Dual analysis framework effectiveness improved by {learning_insights.get('improvement_rate', 5)}%",
        f"Psychological + conversion integration optimized for {extract_industry(state['business_context'])}",
        f"Quality optimization patterns identified across both analysis types"
    ]
    
    print(f"üíæ Memory saved: {len(learning_system.industry_patterns)} total sessions")
    print("üìà Learning completed - Session #" + str(len(learning_system.framework_improvements) + 1))
    
    return state

def format_outputs(state: Level10ResearchState) -> Level10ResearchState:
    """Format final outputs with dual analysis enhancements"""
    
    print("üìÑ Formatting outputs with dual analysis enhancements...")
    
    # Create comprehensive psychology + conversion report
    psychology_report = f"""
# üß† DUAL INTELLIGENCE REPORT: Psychology + Conversion
*Level 10 Enterprise Analysis with Marketing Intelligence*

## üìä Executive Summary
**Session ID:** {state['session_id']}
**Industry Context:** {extract_industry(state['business_context'])}
**Analysis Type:** Dual - Psychological + Conversion Intelligence
**Quality Score:** {state['quality_score']:.1%}
**Confidence Score:** {state['confidence_score']:.1%}

## üéØ Research Approach
‚úÖ Deep psychological analysis revealing unconscious patterns and contradictions
‚úÖ Conversion intelligence transforming psychology into marketing actions
‚úÖ Enhanced interview simulation based on psychological insights
‚úÖ Campaign synthesis combining depth with actionable strategy

## üß† DEEP PSYCHOLOGICAL INTELLIGENCE
{state['psychological_analysis']}

## üéØ CONVERSION INTELLIGENCE APPLICATION
{state['conversion_intelligence']}

## üé≠ ENHANCED CUSTOMER INTERVIEWS
{state['interview_insights']}

## üöÄ CAMPAIGN SYNTHESIS & STRATEGY
{state['synthesis_results']}

## üìà Level 10 Intelligence Metrics
### Dual Analysis Performance:
‚Ä¢ Psychological Analysis Quality: {state['quality_score']:.1%}
‚Ä¢ Conversion Intelligence Quality: {state['confidence_score']:.1%}
‚Ä¢ Industry expertise: {extract_industry(state['business_context'])}
‚Ä¢ Memory patterns applied: {len(state['memory_context'].get('proven_techniques', []))}

### Analysis Completeness:
‚Ä¢ Deep psychological frameworks: ‚úÖ Complete
‚Ä¢ Conversion intelligence generation: ‚úÖ Complete
‚Ä¢ Interview simulation enhancement: ‚úÖ Complete
‚Ä¢ Campaign strategy synthesis: ‚úÖ Complete

### Learning Integration:
‚Ä¢ Similar Research Sessions: {len(state['memory_context'].get('industry_specific_patterns', {}))}
‚Ä¢ Successful Patterns Applied: {len(state['memory_context'].get('framework_best_practices', {}))}
‚Ä¢ Optimization Insights: {len(state['learning_insights'])}

---
*Generated by Level 10 Dual Intelligence System*
*Combining scary-accurate psychology with conversion-driving marketing intelligence*
"""
    
    state["psychology_report"] = psychology_report
    
    # Create campaign insights summary
    state["campaign_insights"] = f"""
üöÄ Dual Intelligence Campaign Summary:
‚Ä¢ Psychology-driven positioning strategy with identity transformation focus
‚Ä¢ Conversion-optimized ad testing hypotheses based on psychological triggers  
‚Ä¢ Content strategy combining emotional depth with conversion mechanisms
‚Ä¢ Offer development psychology with practical implementation roadmap

Quality Assurance: {state['quality_score']:.1%} | Confidence: {state['confidence_score']:.1%}
Analysis Type: Dual - Psychological Depth + Conversion Intelligence
"""
    
    print("‚úÖ Dual analysis output formatting completed")
    
    return state

def extract_voc_patterns(state: Level10ResearchState) -> List[str]:
    """Extract voice of customer patterns from dual analysis"""
    return [
        "frustrated with",
        "tired of", 
        "struggling with",
        "looking for",
        "need to find",
        "want to achieve",
        "ready to invest",
        "willing to pay for"
    ]

def calculate_enhanced_quality_score(state: Level10ResearchState) -> float:
    """Enhanced quality scoring for dual analysis"""
    
    base_score = 0.85
    
    # Psychological depth bonuses
    if len(state.get("psychological_analysis", "")) > 3000:
        base_score += 0.05
    
    # Conversion intelligence bonuses  
    if len(state.get("conversion_intelligence", "")) > 2000:
        base_score += 0.03
        
    # Integration bonuses
    psych_text = state.get("psychological_analysis", "").lower()
    conversion_text = state.get("conversion_intelligence", "").lower()
    
    if "contradiction" in psych_text and "hypothesis" in conversion_text:
        base_score += 0.02  # Good integration bonus
        
    # Interview quality bonus
    interview_text = state.get("interview_insights", "").lower()
    if '"' in interview_text and ":" in interview_text:
        base_score += 0.02
    
    return min(base_score, 0.95)

def calculate_confidence_score(state: Level10ResearchState) -> float:
    """Calculate confidence score based on evidence and validation"""
    base_confidence = 0.80
    
    # Memory context usage boost
    if state["memory_context"].get("framework_best_practices"):
        base_confidence += 0.05
        
    # Dual analysis boost
    if state.get("psychological_analysis") and state.get("conversion_intelligence"):
        base_confidence += 0.05
    
    return min(base_confidence, 0.90)

def create_dual_intelligence_workflow():
    """Create the dual intelligence workflow"""
    
    print("üèóÔ∏è Building Level 10 Dual Intelligence Graph...")
    
    workflow = StateGraph(Level10ResearchState)
    
    # Dual intelligence workflow
    workflow.add_node("set_goal", set_research_goal)
    workflow.add_node("dual_analysis", conduct_dual_analysis_research)  # Psychological + Conversion
    workflow.add_node("enhanced_interviews", simulate_enhanced_interviews)  # Using psychological insights
    workflow.add_node("campaign_synthesis", synthesize_campaign_intelligence)  # Complete integration
    workflow.add_node("learn", learn_from_outcome)
    workflow.add_node("format_outputs", format_outputs)
    
    # Optimized flow
    workflow.set_entry_point("set_goal")
    workflow.add_edge("set_goal", "dual_analysis")
    workflow.add_edge("dual_analysis", "enhanced_interviews")
    workflow.add_edge("enhanced_interviews", "campaign_synthesis")
    workflow.add_edge("campaign_synthesis", "learn")
    workflow.add_edge("learn", "format_outputs")
    workflow.add_edge("format_outputs", END)
    
    print("‚úÖ Level 10 Dual Intelligence Graph created successfully")
    
    return workflow.compile()

# Create the dual intelligence graph instance
graph = create_dual_intelligence_workflow()

# Test function for quality validation
async def test_dual_intelligence_quality(business_context: str, expected_quality: float = 0.9) -> Dict[str, Any]:
    """Test Level 10 Dual Intelligence System quality"""
    
    print("üß™ TESTING LEVEL 10 DUAL INTELLIGENCE SYSTEM")
    print("=" * 60)
    
    # Prepare test state
    test_state = {
        "business_context": business_context,
        "research_type": "comprehensive",
        "output_format": "psychology_report"
    }
    
    start_time = time.time()
    
    # Run the dual intelligence system
    result = graph.invoke(test_state)
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    # Analyze results
    quality_score = result.get("quality_score", 0)
    confidence_score = result.get("confidence_score", 0)
    
    # Test criteria for dual system
    quality_passed = quality_score >= expected_quality
    confidence_passed = confidence_score >= 0.8
    psychological_depth = len(result.get("psychological_analysis", "")) > 3000
    conversion_intelligence = len(result.get("conversion_intelligence", "")) > 2000
    dual_integration = psychological_depth and conversion_intelligence
    
    overall_passed = quality_passed and confidence_passed and dual_integration
    
    test_results = {
        "test_passed": overall_passed,
        "quality_score": quality_score,
        "confidence_score": confidence_score,
        "expected_quality": expected_quality,
        "processing_time": processing_time,
        "psychological_depth": psychological_depth,
        "conversion_intelligence": conversion_intelligence,
        "dual_integration": dual_integration,
        "session_id": result.get("session_id", "unknown")
    }
    
    print(f"üìä DUAL INTELLIGENCE TEST RESULTS:")
    print(f"   Overall: {'‚úÖ PASSED' if overall_passed else '‚ùå FAILED'}")
    print(f"   Quality: {quality_score:.1%} ({'‚úÖ' if quality_passed else '‚ùå'})")
    print(f"   Confidence: {confidence_score:.1%} ({'‚úÖ' if confidence_passed else '‚ùå'})")
    print(f"   Psychological Depth: {'‚úÖ' if psychological_depth else '‚ùå'}")
    print(f"   Conversion Intelligence: {'‚úÖ' if conversion_intelligence else '‚ùå'}")
    print(f"   Dual Integration: {'‚úÖ' if dual_integration else '‚ùå'}")
    print(f"   Processing Time: {processing_time:.1f}s")
    
    return test_results
